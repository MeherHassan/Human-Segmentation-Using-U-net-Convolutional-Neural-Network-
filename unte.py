# -*- coding: utf-8 -*-
"""Copy of Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1obBCtjaNq5Yc5iGppwoHcRWoTXPEkLPx

# MD MEHER HASSAN CHOWDHURY
# 1155645
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np # linear algebra
import pandas as pd

import os
for dirname, _, filenames in os.walk('/content/drive/MyDrive/Assignment2'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import tensorflow as tf
from zipfile import ZipFile 
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import os

print("Train set:  ", len(os.listdir("/content/drive/MyDrive/Assignment2/Training_Images")))#length of folder extracted above in output
print("Train masks:", len(os.listdir("/content/drive/MyDrive/Assignment2/Ground_Truth")))

data_ids = []
paths = []
for dirname, _, filenames in os.walk('/content/drive/MyDrive/Assignment2/Training_Images'):
    for filename in filenames:#images in train folder
        path = os.path.join(dirname, filename)    
        paths.append(path)#images address
        
        train_id = filename.split(".")[0]
        data_ids.append(train_id) #id of train images

d = {"id": data_ids, "train_path": paths}
df = pd.DataFrame(data = d)
df = df.set_index('id')
df2 = df # df containing path to each training image and image unique name as index
df.head(5)



"""# BAD FILE"""

##getiing corrupted files
import os
from os import listdir
from PIL import Image
count=0
for filename in os.listdir('/content/drive/MyDrive/Assignment2/Training_Images'):
    if filename.endswith('jpg'):
     try:
      img=Image.open('/content/drive/MyDrive/Assignment2/Training_Images'+filename)
      img.verify()
     except(IOError,SyntaxError)as e:
         print('Bad file  :  '+filename)
         count=count+1
         print(count)
    if filename.endswith('jpg'):
     try:
      img=Image.open('/content/drive/MyDrive/Assignment2/Training_Images'+filename)
      img.verify()
     except(IOError,SyntaxError)as e:
         print('Bad file for Training Images :  '+filename)
         count=count+1
         print(count)

mask_ids = []
mask_path = []
for dirname, _, filenames in os.walk('/content/drive/MyDrive/Assignment2/Ground_Truth'):
    for filename in filenames: #contents of train_mask folder
        path = os.path.join(dirname, filename)
        mask_path.append(path)  #
        
        mask_id = filename.split(".")[0]
        mask_id = mask_id.split("_mask")[0]
        mask_ids.append(mask_id)

        
d = {"id": mask_ids,"mask_path": mask_path}
mask_df = pd.DataFrame(data = d)
mask_df = mask_df.set_index('id') #containg path to masks of train data and unique id if images as index 
mask_df

mask_df["mask_path"][0]

##getiing corrupted files
import os
from os import listdir
from PIL import Image
count=0
for filename in os.listdir('/content/drive/MyDrive/Assignment2/Ground_Truth'):
    if filename.endswith('jpg'):
     try:
      img=Image.open('/content/drive/MyDrive/Assignment2/Ground_Truth'+filename)
      img.verify()
     except(IOError,SyntaxError)as e:
         print('Bad file  :  '+filename)
         count=count+1
         print(count)
    if filename.endswith('png'):
     try:
      img=Image.open('/content/drive/MyDrive/Assignment2/Ground_Truth'+filename)
      img.verify()
     except(IOError,SyntaxError)as e:
         print('Bad file for Mask Images :  '+filename)
         count=count+1
         print(count)

df["mask_path"] = mask_df["mask_path"]#putting image path and mask path in a single dataframe
df

"""## Augmentation"""

img_size = [64,64]

def data_augmentation(train_img, mask_img):# few data augmentation methods

    if tf.random.uniform(()) > 0.5:#generatin a random condition wih random number between 0 and 1 
        train_img = tf.image.flip_left_right(train_img)
        train_img = tf.image.flip_up_down(train_img)#flipping image from left to right
        train_img = tf.image.random_crop(train_img)
        mask_img = tf.image.flip_left_right(mask_img)#flipping image masks from left to right
        mask_img = tf.image.flip_up_down(mask_img)
        mask_img = tf.image.random_crop(mask_img)

    return train_img, mask_img

def preprocessing(train_path, mask_path):
    train_img = tf.io.read_file(train_path) #reading train image path
    train_img = tf.image.decode_jpeg(train_img, channels=3) #coverting from scalar string tensor to  3d uint8
    train_img = tf.image.resize(train_img, img_size) #resizing it ti use it more conviniently 
    train_img = tf.cast(train_img, tf.float32) / 255.0 # normalizing the pixel values between 0 to 1
    
    mask_img = tf.io.read_file(mask_path)#reading mask path
    mask_img = tf.image.decode_png(mask_img, channels=3)
    mask_img = tf.image.resize(mask_img, img_size)
    mask_img = mask_img[:,:,:1]  #taking use of only one channel  
    mask_img = tf.math.sign(mask_img)
    
    
    return train_img, mask_img
def create_dataset(df, train = False):
    if not train:
        ds = tf.data.Dataset.from_tensor_slices((df["train_path"].values, df["mask_path"].values))#taking path as object
        ds = ds.map(preprocessing, tf.data.AUTOTUNE) #mapping masks to preproessing function
    else:
        ds = tf.data.Dataset.from_tensor_slices((df["train_path"].values, df["mask_path"].values))
        ds = ds.map(preprocessing, tf.data.AUTOTUNE) # mapping images to preprocessing function
        ds = ds.map(data_augmentation, tf.data.AUTOTUNE)# mapping images to data_augmemtation function

    return ds













"""# Without Augmentation"""

img_size = [64,64]


def preprocessing(train_path, mask_path):
    train_img = tf.io.read_file(train_path) #reading train image path
    train_img = tf.image.decode_jpeg(train_img, channels=3) #coverting from scalar string tensor to  3d uint8
    train_img = tf.image.resize(train_img, img_size) #resizing it ti use it more conviniently 
    train_img = tf.cast(train_img, tf.float32) / 255.0 # normalizing the pixel values between 0 to 1
    
    mask_img = tf.io.read_file(mask_path)#reading mask path
    mask_img = tf.image.decode_png(mask_img, channels=3)
    mask_img = tf.image.resize(mask_img, img_size)
    mask_img = mask_img[:,:,:1]  #taking use of only one channel  
    mask_img = tf.math.sign(mask_img)
    
    
    return train_img, mask_img
def create_dataset(df2, train = False):
    if not train:
        ds = tf.data.Dataset.from_tensor_slices((df["train_path"].values, df["mask_path"].values))#taking path as object
        ds = ds.map(preprocessing, tf.data.AUTOTUNE) #mapping masks to preproessing function
    else:
        ds = tf.data.Dataset.from_tensor_slices((df["train_path"].values, df["mask_path"].values))
        ds = ds.map(preprocessing, tf.data.AUTOTUNE) # mapping images to preprocessing function
        #ds = ds.map(data_augmentation, tf.data.AUTOTUNE)# mapping images to data_augmemtation function

    return ds

df2.columns

df.columns

sh = plt.imread(df["mask_path"][0]).shape # real shape of mask 
mask_h = sh[0]#real height of mask images
mask_w = sh[1]#real width of mask images

mask_h

import tensorflow as tf
try:
    AUTOTUNE = tf.data.AUTOTUNE     
except:
    AUTOTUNE = tf.data.experimental.AUTOTUNE

train_df, valid_df = train_test_split(df, random_state=42, test_size=.25)# splitting given labelled data into train and valid 
train = create_dataset(train_df)# train dataset
valid = create_dataset(valid_df)# valid dataset

train_df2, valid_df2 = train_test_split(df2, random_state=42, test_size=.25)# splitting given labelled data into train and valid 
train2 = create_dataset(train_df2)# train dataset
valid2 = create_dataset(valid_df2)# valid dataset

def imshow(img):
    # Convert from tensor image
    plt.imshow(np.transpose(img, (1,2,0)))





TRAIN_LENGTH = len(train_df)#length if train dataset
BATCH_SIZE = 16 # batch size to train images 
BUFFER_SIZE = 1000 #

train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat() # shuffing and batching records
train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE) #fetching data to train
valid_dataset = valid.batch(BATCH_SIZE)

TRAIN_LENGTH2 = len(train_df2)#length if train dataset
BATCH_SIZE = 16 # batch size to train images 
BUFFER_SIZE = 1000 #

train_dataset2 = train2.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat() # shuffing and batching records
train_dataset2 = train_dataset2.prefetch(buffer_size=tf.data.AUTOTUNE) #fetching data to train
valid_dataset2 = valid2.batch(BATCH_SIZE)

def display(display_list): # function for visualizing  images
    plt.figure(figsize=(10, 10)) #size of plot

    title = ['Input Image', 'True Mask', 'Predicted Mask'] #possible images

    for i in range(len(display_list)): 
        plt.subplot(5, len(display_list), i+1) #image, true_mask, predicted_mask
        plt.title(title[i])
        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i])) #function to show images
        plt.axis('off')
    plt.show()

for i in range(4):
   for image, mask in train.take(i): #taking i records
        sample_image, sample_mask = image, mask
        print(sample_image.shape)
        display([sample_image, sample_mask]) #visualizing using above function
        #ax = fig.add_subplot(2, 10/2, idx+1, xticks=[], yticks=[])

import tensorflow as tf
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Dropout 
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Conv2DTranspose
from tensorflow.keras.layers import concatenate
from tensorflow.keras.losses import binary_crossentropy
from sklearn.model_selection import train_test_split

"""# Model Init"""

def EncoderMiniBlock(inputs, n_filters=32, dropout_prob=0.3, max_pooling=True):
    """
    This block uses multiple convolution layers, max pool, relu activation to create an architecture for learning. 
    Dropout can be added for regularization to prevent overfitting. 
    The block returns the activation values for next layer along with a skip connection which will be used in the decoder
    """
    #  2 Conv Layers with relu activation and HeNormal initialization using TensorFlow 
    # Proper initialization prevents from the problem of exploding and vanishing gradients 
    # 'Same' padding will pad the input to conv layer such that the output has the same height and width (hence, is not reduced in size) 
    conv = Conv2D(n_filters, 
                  3,   # Kernel size   
                  activation='relu',
                  padding='same',
                  kernel_initializer='HeNormal')(inputs)
    conv = Conv2D(n_filters, 
                  3,   # Kernel size
                  activation='relu',
                  padding='same',
                  kernel_initializer='HeNormal')(conv)
    
    # Batch Normalization will normalize the output of the last layer based on the batch's mean and standard deviation
    conv = BatchNormalization()(conv, training=False)

    # In case of overfitting, dropout will regularize the loss and gradient computation to shrink the influence of weights on output
    if dropout_prob > 0:     
        conv = tf.keras.layers.Dropout(dropout_prob)(conv)

    # Pooling reduces the size of the image while keeping the number of channels same
    # Pooling has been kept as optional as the last encoder layer does not use pooling (hence, makes the encoder block flexible to use)
    # Below, Max pooling considers the maximum of the input slice for output computation and uses stride of 2 to traverse across input image
    if max_pooling:
        next_layer = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(conv)    
    else:
        next_layer = conv

    # skip connection (without max pooling) will be input to the decoder layer to prevent information loss during transpose convolutions      
    skip_connection = conv
    
    return next_layer, skip_connection

def DecoderMiniBlock(prev_layer_input, skip_layer_input, n_filters=32):
    """
    Decoder Block first uses transpose convolution to upscale the image to a bigger size and then,
    merges the result with skip layer results from encoder block
    Adding 2 convolutions with 'same' padding helps further increase the depth of the network for better predictions
    The function returns the decoded layer output
    """
    # transpose convolution layer to first increase the size of the image
    up = Conv2DTranspose(
                 n_filters,
                 (3,3),    # Kernel size
                 strides=(2,2),
                 padding='same')(prev_layer_input)

    # Merge the skip connection from previous block to prevent information loss
    merge = concatenate([up, skip_layer_input], axis=3)
    
    # 2 Conv Layers with relu activation and HeNormal initialization for further processing
    # The parameters for the function are similar to encoder
    conv = Conv2D(n_filters, 
                 3,     # Kernel size
                 activation='relu',
                 padding='same',
                 kernel_initializer='HeNormal')(merge)
    conv = Conv2D(n_filters,
                 3,   # Kernel size
                 activation='relu',
                 padding='same',
                 kernel_initializer='HeNormal')(conv)
    return conv

# Compile U-Net Blocks
def UNetCompiled(input_size=(128, 128, 3), n_filters=16, n_classes=1):
    inputs = Input(input_size)
    
    # Encoder includes multiple convolutional mini blocks with different maxpooling, dropout and filter parameters
    # filters are increasing as we go deeper into the network which will increasse the # channels of the image 
    cblock1 = EncoderMiniBlock(inputs, n_filters,dropout_prob=0, max_pooling=True)
    cblock2 = EncoderMiniBlock(cblock1[0],n_filters*2,dropout_prob=0, max_pooling=True)
    cblock3 = EncoderMiniBlock(cblock2[0], n_filters*4,dropout_prob=0, max_pooling=True)
    cblock4 = EncoderMiniBlock(cblock3[0], n_filters*8,dropout_prob=0.3, max_pooling=True)
    cblock5 = EncoderMiniBlock(cblock4[0], n_filters*16, dropout_prob=0.3, max_pooling=False) 
    
    # Decoder includes multiple mini blocks with decreasing number of filters
    # Observe the skip connections from the encoder are given as input to the decoder
    # Recall the 2nd output of encoder block was skip connection, hence cblockn[1] is used
    ublock6 = DecoderMiniBlock(cblock5[0], cblock4[1],  n_filters * 8)
    ublock7 = DecoderMiniBlock(ublock6, cblock3[1],  n_filters * 4)
    ublock8 = DecoderMiniBlock(ublock7, cblock2[1],  n_filters * 2)
    ublock9 = DecoderMiniBlock(ublock8, cblock1[1],  n_filters)
 
    #  1 3x3 convolution layer (Same as the prev Conv Layers)
    # Followed by a 1x1 Conv layer to get the image to the desired size. 
    # Observe the number of channels will be equal to number of output classes
    conv9 = Conv2D(n_filters,
                 3,
                 activation='relu',
                 padding='same',
                 kernel_initializer='he_normal')(ublock9)

    conv10 = Conv2D(n_classes, 1, padding='same')(conv9)
    
    # Defining the model
    model = tf.keras.Model(inputs=inputs, outputs=conv10)

    return model

#compiling unet model
unet = UNetCompiled(input_size=(64,64,3), n_filters=16, n_classes=1)

from keras.losses import binary_crossentropy
import keras.backend as K

#metric and loss function to be used for training model
def dice_coeff(y_true, y_pred):
    smooth = 1.
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)
    return score


def dice_loss(y_true, y_pred):
    loss = 1 - dice_coeff(y_true, y_pred)
    return loss


def bce_dice_loss(y_true, y_pred):
    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)
    return loss

unet.compile(optimizer=tf.keras.optimizers.Adam(), 
             loss=tf.keras.losses.BinaryCrossentropy(),
              metrics=['accuracy'])

STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE

from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

callbacks = [
    EarlyStopping(patience=10, verbose=1),
    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),
    ModelCheckpoint('modelBest', verbose=1, save_best_only=True, save_weights_only=True)
]





hist = unet.fit(train_dataset2, batch_size=16, epochs=100,steps_per_epoch=STEPS_PER_EPOCH, validation_data=valid_dataset)

##plotting accuracy and loss
def plot_graphs(history, string):
  plt.plot(history.history[string])
  plt.plot(history.history['val_'+string])
  plt.title(string)
  plt.xlabel("Epochs")
  plt.ylabel(string)
  plt.legend([string, 'val_'+string])
  plt.show()

plot_graphs(hist, "accuracy")
plot_graphs(hist, "loss")

"""# Without Early STopping"""

hist = unet.fit(train_dataset, batch_size=16, epochs=100,steps_per_epoch=STEPS_PER_EPOCH, validation_data=valid_dataset)

##plotting accuracy and loss
def plot_graphs(history, string):
  plt.plot(history.history[string])
  plt.plot(history.history['val_'+string])
  plt.title(string)
  plt.xlabel("Epochs")
  plt.ylabel(string)
  plt.legend([string, 'val_'+string])
  plt.show()

plot_graphs(hist, "accuracy")
plot_graphs(hist, "loss")

"""# With Early Stopping"""

hist = unet.fit(train_dataset, batch_size=16, epochs=100,steps_per_epoch=STEPS_PER_EPOCH,callbacks = callbacks, validation_data=valid_dataset)

##plotting accuracy and loss
def plot_graphs(history, string):
  plt.plot(history.history[string])
  plt.plot(history.history['val_'+string])
  plt.title(string)
  plt.xlabel("Epochs")
  plt.ylabel(string)
  plt.legend([string, 'val_'+string])
  plt.show()

plot_graphs(hist, "accuracy")
plot_graphs(hist, "loss")

#loading the weight of model which last performed  best
unet.load_weights("./modelBest")

from torchvision import transforms

def vis_compare(dataset=valid_dataset,num_case=1):
       
    for sample in dataset.take(1):
        image, label = sample[0].numpy(), sample[1].numpy()
        print(image.shape)
        print(label.shape)
    preds=unet.predict(image)#predicting mask of valid dataset
    #preds = np.squeeze(preds, axis =-1)
    print(preds.shape)
    if num_case>1:
        cases=[j for j in np.random.choice(image.shape[0],size=num_case,replace=False)]   #choosing random images
        for i in cases:
            truth=(image[i],label[i])
            pred=(image[i],preds[i])
            print(f"case_number_{i}")
            fig, arr = plt.subplots(1, 3, figsize=(15, 15))
            arr[0].imshow(image[i])
            arr[0].set_title('Processed Image')
            arr[1].imshow(label[i])
            arr[1].set_title('Actual Masked Image ')
            arr[2].imshow(preds[i])
            arr[2].set_title('Predicted Masked Image ')
    else:
        truth=(image[0],label[0])
        pred=(image[0],preds[0])
        display([image[0],label[0],preds[0]])
            
    
    
    plt.show()

"""# Prediction"""

vis_compare(dataset=valid_dataset,num_case=1)



"""# Table"""

pip install tabulate

# import module
from tabulate import tabulate
 
# assign data
mydata = [
    ["Without Augmentation", "90","24"],
    ["With Augmentation Without Early Stopping", "90","25"],
    ["With Augmentation With Early Stopping", "93","17"]
]
 
# create header
head = ["Model", "Accuracy","Loss"]
 
# display table
print(tabulate(mydata, headers=head, tablefmt="grid"))